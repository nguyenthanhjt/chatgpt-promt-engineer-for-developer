{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3993515-9710-4ac4-89e9-b35ebb81e920",
   "metadata": {
    "id": "rhqRhkElpJ0z"
   },
   "source": [
    "# Setting up Environment\n",
    "\n",
    "In this notebook, we will set up the environment required for running example with Jupyter Notebook.\n",
    "\n",
    "These steps need to be done at the beginning of each notebook as prerequisite | pre-conditions.\n",
    "\n",
    "## Set up steps\n",
    "1. Import necessary libraries\n",
    "2. Load environment variables\n",
    "3. Set the OpenAI API key\n",
    "4. Define a function to get completions from the OpenAI API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import-libraries",
   "metadata": {},
   "source": [
    "### Step 1: Import necessary libraries\n",
    "\n",
    "In this step, we will import the libraries required for our environment setup. We need the `openai` library to interact with the OpenAI API and the `os` library to handle environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41df0348",
   "metadata": {
    "height": 132,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-env-variables",
   "metadata": {},
   "source": [
    "### Step 2: Load environment variables\n",
    "\n",
    "In this step, we will load the environment variables from a `.env` file. This file should contain our OpenAI API key and any other configuration settings we need. We use the `dotenv` library to read the `.env` file and load the variables into the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ab218c7254ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "set-api-key",
   "metadata": {},
   "source": [
    "### Step 3: Set the OpenAI API key\n",
    "\n",
    "In this step, we will set the OpenAI API key. This key is required to authenticate our requests to the OpenAI API. We can either set it by reading from the environment variables or by directly assigning the key in the code. For security reasons, it is recommended to use environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d7739eb3e64754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure OS environment variable to store Open API Key\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Directly setting\n",
    "openai.api_key = \"sk-\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "define-function",
   "metadata": {},
   "source": [
    "### Step 4: Define a function to get completions from the OpenAI API\n",
    "\n",
    "In this step, we will define a function `get_completion` that takes a prompt and returns a completion from the OpenAI API. The function sends a request to the API with the given prompt and model, and returns the response. We use the `gpt-3.5-turbo` model by default, but this can be changed by passing a different model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f5d563bfddd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_completionWithTemperature(prompt, model=\"gpt-3.5-turbo\",temperature=0): # Andrew mentioned that the prompt/ completion paradigm is preferable for this class\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ],
   "id": "4dd1180f2ebf9975"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
