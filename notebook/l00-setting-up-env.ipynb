{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3993515-9710-4ac4-89e9-b35ebb81e920",
   "metadata": {
    "id": "rhqRhkElpJ0z"
   },
   "source": [
    "# Setting up Environment\n",
    "\n",
    "In this notebook, we will set up the environment required for running example with Jupyter Notebook.\n",
    "\n",
    "These steps need to be done at the beginning of each notebook as prerequisite | pre-conditions.\n",
    "\n",
    "## Set up steps\n",
    "1. Import necessary libraries\n",
    "2. Set the OpenAI API key\n",
    "3. Define a function to get completions from the OpenAI API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import-libraries",
   "metadata": {},
   "source": [
    "### Step 1: Import necessary libraries\n",
    "\n",
    "In this step, we will import the libraries required for our environment setup. We need the `openai` library to interact with the OpenAI API and the `os` library to handle environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41df0348",
   "metadata": {
    "height": 132,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-env-variables",
   "metadata": {},
   "source": [
    "### Step 2: Set the OpenAI API key\n",
    "\n",
    "OpenAI Key: this key is required to authenticate our requests to the OpenAI API. We can either set it by reading from the environment variables or by directly assigning the key in the code. For security reasons, it is recommended to use environment variables.\n",
    "\n",
    "#### Optional 1: Load environment variables\n",
    "\n",
    "Load the environment variables from a `.env` file. This file should contain our OpenAI API key and any other configuration settings we need. We use the `dotenv` library to read the `.env` file and load the variables into the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ab218c7254ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "# Configure OS environment variable to store Open API Key\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "set-api-key",
   "metadata": {},
   "source": [
    "#### Optional 2: Get & Set the OpenAI API key directly\n",
    "To get openai api key: access to [OpenAI Account profile](https://platform.openai.com/settings/profile?tab=api-keysIn) \n",
    "\n",
    "Set the OpenAI API key directly to the property `api_key` of `openai`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d7739eb3e64754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directly setting\n",
    "openai.api_key = \"sk-\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "define-function",
   "metadata": {},
   "source": [
    "### Step 4: Define a function to get completions from the OpenAI API\n",
    "\n",
    "In this step, we will define a function `get_completion` that takes a prompt and returns a completion from the OpenAI API. The function sends a request to the API with the given prompt and model, and returns the response. We use the `gpt-3.5-turbo` model by default, but this can be changed by passing a different model name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f5d563bfddd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To use a higher temperature: we will define a function `get_completionWithTemperature` that takes a more parameter `temperature` - positive number start from 0",
   "id": "751d85283cb421e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_completionWithTemperature(prompt, model=\"gpt-3.5-turbo\",temperature=0): # Andrew mentioned that the prompt/ completion paradigm is preferable for this class\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ],
   "id": "396b62ff3c13ac98"
  },
  {
   "cell_type": "markdown",
   "id": "define-function-with-temperature",
   "metadata": {},
   "source": [
    "### Step 4.1: Define a function to get completions from the OpenAI API with temperature\n",
    "\n",
    "This function is similar to `get_completion`, but it includes an additional parameter `temperature` which controls the randomness of the model's output. A higher temperature value will result in more random outputs, while a lower value will make the output more deterministic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee73e99beca415f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completionWithTemperature(prompt, model=\"gpt-3.5-turbo\", temperature=0):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
